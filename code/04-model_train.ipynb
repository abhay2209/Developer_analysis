{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb  \n",
    "import constants as cs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, make_scorer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn # to check the version\n",
    "# print(sklearn.__version__)\n",
    "# print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename: str) -> pd.DataFrame:\n",
    "    with zipfile.ZipFile(f\"../{filename}.zip\") as data_zip:\n",
    "        with data_zip.open(f\"{filename}.csv\") as developer_data:\n",
    "            return pd.read_csv(developer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_data = load_data(cs.NA_TRAIN_DATA)\n",
    "\n",
    "compensation = na_data[cs.COMPENSATION]\n",
    "X_data = na_data.drop(columns=[cs.COMPENSATION])\n",
    "\n",
    "print(X_data.columns)\n",
    "# Create columns for job title and organisation size\n",
    "X_data = pd.get_dummies(X_data)\n",
    "print(X_data.columns)\n",
    "print(X_data.shape)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_data, compensation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Feature scaling for models that need scaled data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_model_filename = f'{cs.ML_MODELS_FOLDER}/scaler.pkl'\n",
    "joblib.dump(scaler, scaler_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_accuracy_score(y_true, y_pred):\n",
    "        accuracy_count = 0\n",
    "        for true_val, pred_val in zip(y_true, y_pred):\n",
    "            if abs(true_val - pred_val) <= 15000:\n",
    "                accuracy_count += 1\n",
    "\n",
    "        accuracy = accuracy_count / len(y_true)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameter grid\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [150, 200],\n",
    "    'max_depth': [75, 100, 125, 150],\n",
    "    'min_samples_leaf': [10, 20, 30]\n",
    "}\n",
    "# Create an empty list to store the results of each model and also the best model so it can be resused\n",
    "results = []\n",
    "rf_models = []\n",
    "\n",
    "# Iterate through the parameter grid and perform GridSearchCV for each combination\n",
    "for params in ParameterGrid(rf_param_grid):\n",
    "    # Create and fit the model\n",
    "    rf_model = RandomForestRegressor(**params)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_models.append(rf_model)\n",
    "\n",
    "    rf_custom_score_train = custom_accuracy_score(y_train, rf_model.predict(X_train))\n",
    "    rf_custom_score_valid = custom_accuracy_score(y_valid, rf_model.predict(X_valid))\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        cs.TRAINING_SCORE: rf_custom_score_train,\n",
    "        cs.VALIDATION_SCORE: rf_custom_score_valid\n",
    "    })\n",
    "\n",
    "# Plot the results on a graph\n",
    "train_scores = [result[cs.TRAINING_SCORE] for result in results]\n",
    "valid_scores = [result[cs.VALIDATION_SCORE] for result in results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(results)), train_scores, label='Training Score', marker='o')\n",
    "plt.plot(range(len(results)), valid_scores, label='Validation Score', marker='o')\n",
    "# plt.xticks(range(len(results)), [str(result['params']) for result in results], rotation=45)\n",
    "plt.title('Random Forest Models')\n",
    "plt.xlabel('Model Parameters')\n",
    "plt.ylabel('Custom Score')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{cs.ML_MODELS_FOLDER}/{cs.RANDOM_FOREST_MODELS}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model = rf_models[12] \n",
    "print(results[12])\n",
    "print(results[8])\n",
    "# max depth 125 min sample leaf 10 n estimators 150\n",
    "best_rf_model_filename = f'{cs.ML_MODELS_FOLDER}/{cs.BEST_RF_MODELS}.pkl'\n",
    "joblib.dump(best_rf_model, best_rf_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with an svr model \n",
    "results = []\n",
    "svr_models = []\n",
    "\n",
    "svr_param_grid = {\n",
    "        'C': [1, 10, 100],\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "\n",
    "for params in ParameterGrid(svr_param_grid):\n",
    "    svr_model = SVR(**params)\n",
    "    svr_model.fit(X_train_scaled, y_train)\n",
    "    svr_models.append(svr_model)\n",
    "\n",
    "    svr_custom_score_train = custom_accuracy_score(y_train, svr_model.predict(X_train_scaled))\n",
    "    svr_custom_score_valid = custom_accuracy_score(y_valid, svr_model.predict(X_valid_scaled))\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        cs.TRAINING_SCORE: svr_custom_score_train,\n",
    "        cs.VALIDATION_SCORE: svr_custom_score_valid\n",
    "    })\n",
    "\n",
    "# Plot the results on a graph\n",
    "train_scores = [result[cs.TRAINING_SCORE] for result in results]\n",
    "valid_scores = [result[cs.VALIDATION_SCORE] for result in results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(results)), train_scores, label='Training Score', marker='o')\n",
    "plt.plot(range(len(results)), valid_scores, label='Validation Score', marker='o')\n",
    "plt.title('SVR Models')\n",
    "plt.xlabel('Model Parameters')\n",
    "plt.ylabel('Custom Score')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{cs.ML_MODELS_FOLDER}/{cs.SVR_MODELS}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svr_model = svr_models[20]\n",
    "print(results[20])\n",
    "# C 100 ,gamma auto, kernel linear\n",
    "best_svr_model_filename = f'{cs.ML_MODELS_FOLDER}/{cs.BEST_SVR_MODELS}.pkl'\n",
    "joblib.dump(best_svr_model, best_svr_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "gb_models = []\n",
    "gb_param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 10]\n",
    "    }\n",
    "for params in ParameterGrid(gb_param_grid):\n",
    "    gb_model = GradientBoostingRegressor(**params)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    gb_models.append(gb_model)\n",
    "\n",
    "    # Calculate custom scoring for training and validation data\n",
    "    gb_custom_score_train = custom_accuracy_score(y_train, gb_model.predict(X_train))\n",
    "    gb_custom_score_valid = custom_accuracy_score(y_valid, gb_model.predict(X_valid))\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        cs.TRAINING_SCORE: gb_custom_score_train,\n",
    "        cs.VALIDATION_SCORE: gb_custom_score_valid\n",
    "    })\n",
    "\n",
    "# Plot the results on a graph\n",
    "train_scores = [result[cs.TRAINING_SCORE] for result in results]\n",
    "valid_scores = [result[cs.VALIDATION_SCORE] for result in results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(results)), train_scores, label='Training Score', marker='o')\n",
    "plt.plot(range(len(results)), valid_scores, label='Validation Score', marker='o')\n",
    "# plt.xticks(range(len(results)), [str(result['params']) for result in results], rotation=45)\n",
    "plt.title('Gradient Boost models')\n",
    "plt.xlabel('Model Parameters')\n",
    "plt.ylabel('Custom Score')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{cs.ML_MODELS_FOLDER}/{cs.GB_MODELS}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gb_model = gb_models[12]\n",
    "print(results[12])\n",
    "# same as xg boost\n",
    "best_gb_model_filename = f'{cs.ML_MODELS_FOLDER}/{cs.BEST_GB_MODELS}.pkl'\n",
    "joblib.dump(best_gb_model, best_gb_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "xgb_models = []\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 10]\n",
    "}\n",
    "\n",
    "for params in ParameterGrid(xgb_param_grid):\n",
    "    xgb_model = xgb.XGBRegressor(**params)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    xgb_models.append(xgb_model)\n",
    "\n",
    "    # Calculate custom scoring for training and validation data\n",
    "    xgb_custom_score_train = custom_accuracy_score(y_train, xgb_model.predict(X_train))\n",
    "    xgb_custom_score_valid = custom_accuracy_score(y_valid, xgb_model.predict(X_valid))\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        cs.TRAINING_SCORE: xgb_custom_score_train,\n",
    "        cs.VALIDATION_SCORE: xgb_custom_score_valid\n",
    "    })\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(results)), train_scores, label='Training Score', marker='o')\n",
    "plt.plot(range(len(results)), valid_scores, label='Validation Score', marker='o')\n",
    "# plt.xticks(range(len(results)), [str(result['params']) for result in results], rotation=45)\n",
    "plt.title('XGboost models')\n",
    "plt.xlabel('Model Parameters')\n",
    "plt.ylabel('Custom Score')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(F\"{cs.ML_MODELS_FOLDER}/{cs.XGBOOST_MODELS}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost_model = xgb_models[12]\n",
    "print(results[12])\n",
    "#paraemters larning rate 0.05, max depth 5, n estimators 100\n",
    "best_xgboost_model_filename = f'{cs.ML_MODELS_FOLDER}/{cs.BEST_XGBOOST_MODELS}.pkl'\n",
    "joblib.dump(best_xgboost_model, best_xgboost_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "X_valid.to_csv(f\"X_valid_data.csv\", index=False)\n",
    "with zipfile.ZipFile(f\"../X_valid_data.zip\", 'w') as zipf:\n",
    "    zipf.write(f\"X_valid_data.csv\")\n",
    "os.remove(f\"X_valid_data.csv\")\n",
    "y_valid.to_csv(f\"y_valid_data.csv\", index=False)\n",
    "\n",
    "with zipfile.ZipFile(f\"../y_valid_data.zip\", 'w') as zipf:\n",
    "    zipf.write(f\"y_valid_data.csv\")\n",
    "os.remove(f\"y_valid_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid.to_csv(f\"X_train_data.csv\", index=False)\n",
    "with zipfile.ZipFile(f\"../X_train_data.zip\", 'w') as zipf:\n",
    "    zipf.write(f\"X_train_data.csv\")\n",
    "os.remove(f\"X_train_data.csv\")\n",
    "y_valid.to_csv(f\"y_train_data.csv\", index=False)\n",
    "with zipfile.ZipFile(f\"../y_train_data.zip\", 'w') as zipf:\n",
    "    zipf.write(f\"y_train_data.csv\")\n",
    "os.remove(f\"y_train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39m# to check the version\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(sklearn\u001b[39m.\u001b[39m__version__)\n\u001b[0;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(xgb\u001b[39m.\u001b[39m__version__)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "# import sklearn # to check the version\n",
    "# print(sklearn.__version__)\n",
    "# print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_data = load_data(cs.NA_TRAIN_DATA)\n",
    "\n",
    "compensation = na_data[cs.COMPENSATION]\n",
    "X_data = na_data.drop(columns=[cs.COMPENSATION])\n",
    "\n",
    "print(X_data.columns)\n",
    "# Create columns for job title and organisation size\n",
    "X_data = pd.get_dummies(X_data)\n",
    "print(X_data.columns)\n",
    "print(X_data.shape)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_data, compensation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_model_filename = f'{cs.ML_MODELS_FOLDER}/scaler.pkl'\n",
    "joblib.dump(scaler, scaler_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameter grid\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [150, 200],\n",
    "    'max_depth': [75, 100, 125, 150],\n",
    "    'min_samples_leaf': [10, 20, 30]\n",
    "}\n",
    "# Create an empty list to store the results of each model and also the best model so it can be resused\n",
    "results = []\n",
    "rf_models = []\n",
    "\n",
    "# Iterate through the parameter grid and perform GridSearchCV for each combination\n",
    "for params in ParameterGrid(rf_param_grid):\n",
    "    # Create and fit the model\n",
    "    rf_model = RandomForestRegressor(**params)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_models.append(rf_model)\n",
    "\n",
    "    rf_custom_score_train = custom_accuracy_score(y_train, rf_model.predict(X_train))\n",
    "    rf_custom_score_valid = custom_accuracy_score(y_valid, rf_model.predict(X_valid))\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        cs.TRAINING_SCORE: rf_custom_score_train,\n",
    "        cs.VALIDATION_SCORE: rf_custom_score_valid\n",
    "    })\n",
    "\n",
    "# Plot the results on a graph\n",
    "train_scores = [result[cs.TRAINING_SCORE] for result in results]\n",
    "valid_scores = [result[cs.VALIDATION_SCORE] for result in results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(results)), train_scores, label='Training Score', marker='o')\n",
    "plt.plot(range(len(results)), valid_scores, label='Validation Score', marker='o')\n",
    "# plt.xticks(range(len(results)), [str(result['params']) for result in results], rotation=45)\n",
    "plt.title('Random Forest Models')\n",
    "plt.xlabel('Model Parameters')\n",
    "plt.ylabel('Custom Score')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{cs.ML_MODELS_FOLDER}/{cs.RANDOM_FOREST_MODELS}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with an svr model \n",
    "results = []\n",
    "svr_models = []\n",
    "\n",
    "svr_param_grid = {\n",
    "        'C': [1, 10, 100],\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "\n",
    "for params in ParameterGrid(svr_param_grid):\n",
    "    # Set the parameters for the RandomForestRegressor in the pipeline\n",
    "    svr_model = SVR(**params)\n",
    "    svr_model.fit(X_train_scaled, y_train)\n",
    "    svr_models.append(svr_model)\n",
    "\n",
    "    # Calculate custom scoring for training and validation data\n",
    "    svr_custom_score_train = custom_accuracy_score(y_train, svr_model.predict(X_train_scaled))\n",
    "    svr_custom_score_valid = custom_accuracy_score(y_valid, svr_model.predict(X_valid_scaled))\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        cs.TRAINING_SCORE: svr_custom_score_train,\n",
    "        cs.VALIDATION_SCORE: svr_custom_score_valid\n",
    "    })\n",
    "\n",
    "# Plot the results on a graph\n",
    "train_scores = [result[cs.TRAINING_SCORE] for result in results]\n",
    "valid_scores = [result[cs.VALIDATION_SCORE] for result in results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(results)), train_scores, label='Training Score', marker='o')\n",
    "plt.plot(range(len(results)), valid_scores, label='Validation Score', marker='o')\n",
    "# plt.xticks(range(len(results)), [str(result['params']) for result in results], rotation=45)\n",
    "plt.title('SVR Models')\n",
    "plt.xlabel('Model Parameters')\n",
    "plt.ylabel('Custom Score')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{cs.ML_MODELS_FOLDER}/{cs.SVR_MODELS}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "gb_models = []\n",
    "gb_param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 10]\n",
    "    }\n",
    "for params in ParameterGrid(gb_param_grid):\n",
    "    gb_model = GradientBoostingRegressor(**params)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    gb_models.append(gb_model)\n",
    "\n",
    "    # Calculate custom scoring for training and validation data\n",
    "    gb_custom_score_train = custom_accuracy_score(y_train, gb_model.predict(X_train))\n",
    "    gb_custom_score_valid = custom_accuracy_score(y_valid, gb_model.predict(X_valid))\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        cs.TRAINING_SCORE: gb_custom_score_train,\n",
    "        cs.VALIDATION_SCORE: gb_custom_score_valid\n",
    "    })\n",
    "\n",
    "# Plot the results on a graph\n",
    "train_scores = [result[cs.TRAINING_SCORE] for result in results]\n",
    "valid_scores = [result[cs.VALIDATION_SCORE] for result in results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(results)), train_scores, label='Training Score', marker='o')\n",
    "plt.plot(range(len(results)), valid_scores, label='Validation Score', marker='o')\n",
    "# plt.xticks(range(len(results)), [str(result['params']) for result in results], rotation=45)\n",
    "plt.title('Gradient Boost models')\n",
    "plt.xlabel('Model Parameters')\n",
    "plt.ylabel('Custom Score')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{cs.ML_MODELS_FOLDER}/{cs.GB_MODELS}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "xgb_models = []\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 10]\n",
    "}\n",
    "\n",
    "for params in ParameterGrid(xgb_param_grid):\n",
    "    xgb_model = xgb.XGBRegressor(**params)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    xgb_models.append(xgb_model)\n",
    "\n",
    "    # Calculate custom scoring for training and validation data\n",
    "    xgb_custom_score_train = custom_accuracy_score(y_train, xgb_model.predict(X_train))\n",
    "    xgb_custom_score_valid = custom_accuracy_score(y_valid, xgb_model.predict(X_valid))\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        cs.TRAINING_SCORE: xgb_custom_score_train,\n",
    "        cs.VALIDATION_SCORE: xgb_custom_score_valid\n",
    "    })\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(results)), train_scores, label='Training Score', marker='o')\n",
    "plt.plot(range(len(results)), valid_scores, label='Validation Score', marker='o')\n",
    "# plt.xticks(range(len(results)), [str(result['params']) for result in results], rotation=45)\n",
    "plt.title('XGboost models')\n",
    "plt.xlabel('Model Parameters')\n",
    "plt.ylabel('Custom Score')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(F\"{cs.ML_MODELS_FOLDER}/{cs.XGBOOST_MODELS}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "X_valid.to_csv(f\"X_valid_data.csv\", index=False)\n",
    "with zipfile.ZipFile(f\"../X_valid_data.zip\", 'w') as zipf:\n",
    "    zipf.write(f\"X_valid_data.csv\")\n",
    "os.remove(f\"X_valid_data.csv\")\n",
    "y_valid.to_csv(f\"y_valid_data.csv\", index=False)\n",
    "\n",
    "with zipfile.ZipFile(f\"../y_valid_data.zip\", 'w') as zipf:\n",
    "    zipf.write(f\"y_valid_data.csv\")\n",
    "os.remove(f\"y_valid_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
